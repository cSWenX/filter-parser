#!/usr/bin/env python3
"""
Real Image Analysis Server - ä½¿ç”¨OpenCVè¿›è¡ŒçœŸå®å›¾åƒåˆ†æ
"""
import http.server
import socketserver
import json
import os
import time
import tempfile
import hashlib
from datetime import datetime
import cv2
import numpy as np
from PIL import Image
import cgi

class ImageAnalysisHandler(http.server.SimpleHTTPRequestHandler):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, directory="/Users/cswenx/program/AICoding/Filter-Parser", **kwargs)

    def end_headers(self):
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', 'Content-Type, Authorization')
        super().end_headers()

    def do_OPTIONS(self):
        print("Received OPTIONS request")
        self.send_response(200)
        self.end_headers()

    def do_POST(self):
        print(f"POST: {self.path}")
        if self.path.startswith('/api/'):
            self.handle_api_post()
        else:
            self.send_error(404)

    def do_GET(self):
        print(f"GET: {self.path}")
        if self.path.startswith('/api/'):
            self.handle_api_get()
        else:
            super().do_GET()

    def handle_api_post(self):
        api_path = self.path.replace('/api', '')
        if '?' in api_path:
            api_path = api_path.split('?')[0]

        print(f"API POST Path: {api_path}")

        if api_path == '/upload':
            self.handle_upload()
        elif api_path.startswith('/analyze/'):
            self.handle_analyze(api_path)
        elif api_path == '/generate':
            self.handle_generate()
        elif api_path == '/health':
            self.handle_health()
        else:
            self.send_json_error(404, "API endpoint not found")

    def handle_api_get(self):
        api_path = self.path.replace('/api', '')
        if '?' in api_path:
            api_path = api_path.split('?')[0]

        print(f"API GET Path: {api_path}")

        if api_path == '/health':
            self.handle_health()
        elif api_path.startswith('/download/'):
            self.handle_download(api_path)
        elif api_path.startswith('/preview/'):
            self.handle_preview(api_path)
        else:
            self.send_json_error(404, "API endpoint not found")

    def handle_upload(self):
        print("=== UPLOAD REQUEST ===")
        print(f"Method: {self.command}")
        print(f"Headers: {dict(self.headers)}")

        try:
            # è§£æmultipart form data
            form = cgi.FieldStorage(
                fp=self.rfile,
                headers=self.headers,
                environ={'REQUEST_METHOD': 'POST'}
            )

            if 'image' in form:
                file_item = form['image']
                if file_item.filename:
                    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
                    temp_dir = tempfile.gettempdir()
                    file_data = file_item.file.read()

                    # ç”ŸæˆåŸºäºæ–‡ä»¶å†…å®¹çš„IDï¼ˆç¡®ä¿åŒä¸€æ–‡ä»¶æ€»æ˜¯åŒä¸€IDï¼‰
                    file_hash = hashlib.md5(file_data).hexdigest()
                    image_id = f"img_{file_hash[:12]}"

                    # ä¿å­˜æ–‡ä»¶
                    temp_path = os.path.join(temp_dir, f"{image_id}.jpg")
                    with open(temp_path, 'wb') as f:
                        f.write(file_data)

                    print(f"Image saved to: {temp_path}")
                    print(f"Image ID: {image_id}")

                    response_data = {
                        "status": "success",
                        "message": "ä¸Šä¼ æˆåŠŸ",
                        "data": {
                            "image_id": image_id,
                            "filename": file_item.filename,
                            "file_size": len(file_data),
                            "dimensions": self.get_image_dimensions(temp_path)
                        }
                    }
                else:
                    response_data = {
                        "status": "error",
                        "message": "æ²¡æœ‰é€‰æ‹©æ–‡ä»¶"
                    }
            else:
                response_data = {
                    "status": "error",
                    "message": "æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶"
                }

            print("Sending upload response")
            self.send_json_response(response_data)

        except Exception as e:
            print(f"Upload error: {e}")
            self.send_json_error(500, f"Upload failed: {str(e)}")

    def get_image_dimensions(self, image_path):
        """è·å–å›¾ç‰‡å°ºå¯¸"""
        try:
            img = cv2.imread(image_path)
            height, width = img.shape[:2]
            return [width, height]
        except:
            return [800, 600]  # é»˜è®¤å°ºå¯¸

    def analyze_image_with_opencv(self, image_path):
        """ä½¿ç”¨OpenCVè¿›è¡ŒçœŸå®çš„å›¾åƒåˆ†æ"""
        try:
            print(f"Analyzing image: {image_path}")

            # è¯»å–å›¾åƒ
            img = cv2.imread(image_path)
            if img is None:
                raise ValueError("æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶")

            # è½¬æ¢é¢œè‰²ç©ºé—´
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            img_lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)

            # 1. å¢å¼ºäº®åº¦åˆ†æ - ä½¿ç”¨å¤šç§æŒ‡æ ‡
            brightness_metrics = self.analyze_brightness_advanced(img_gray, img_lab)
            brightness_adjust = self.calculate_brightness_adjustment_advanced(brightness_metrics)

            # 2. å¢å¼ºå¯¹æ¯”åº¦åˆ†æ - å±€éƒ¨å¯¹æ¯”åº¦ + å…¨å±€å¯¹æ¯”åº¦
            contrast_metrics = self.analyze_contrast_advanced(img_gray)
            contrast_adjust = self.calculate_contrast_adjustment_advanced(contrast_metrics)

            # 3. å¢å¼ºé¥±å’Œåº¦åˆ†æ - HSV + LABåŒé‡åˆ†æ
            saturation_metrics = self.analyze_saturation_advanced(img_hsv, img_lab)
            saturation_adjust = self.calculate_saturation_adjustment_advanced(saturation_metrics)

            # 4. å¢å¼ºé”åŒ–åˆ†æ - å¤šå°ºåº¦é”åº¦æ£€æµ‹
            sharpness_metrics = self.analyze_sharpness_advanced(img_gray)
            sharpness_adjust = self.calculate_sharpness_adjustment_advanced(sharpness_metrics)

            # 5. å¢å¼ºè‰²æ¸©åˆ†æ - ç™½å¹³è¡¡ç®—æ³•
            temperature_metrics = self.analyze_temperature_advanced(img_rgb)
            temperature_adjust = self.calculate_temperature_adjustment_advanced(temperature_metrics)

            # 6. å¢å¼ºè‰²è°ƒåˆ†æ - ä¸»å¯¼è‰²è°ƒæ£€æµ‹
            hue_metrics = self.analyze_hue_advanced(img_hsv)
            hue_adjust = self.calculate_hue_adjustment_advanced(hue_metrics)

            # 7. å¢å¼ºé˜´å½±/é«˜å…‰åˆ†æ - åŒºåŸŸæ€§åˆ†æ
            shadow_highlight_metrics = self.analyze_shadow_highlight_advanced(img_gray, img_rgb)
            shadow_adjust, highlight_adjust = self.calculate_shadow_highlight_adjustment_advanced(shadow_highlight_metrics)

            # 8. ç”Ÿæˆæ™ºèƒ½å»ºè®®
            suggestions = self.generate_intelligent_suggestions_advanced(
                brightness_metrics, contrast_metrics, saturation_metrics,
                sharpness_metrics, temperature_metrics, hue_metrics
            )

            return {
                "brightness": {
                    "name": "äº®åº¦",
                    "direction": "å¢åŠ " if brightness_adjust > 0 else "é™ä½" if brightness_adjust < 0 else "é€‚ä¸­",
                    "value": brightness_adjust,
                    "unit": "%",
                    "reference": f"å¹³å‡äº®åº¦: {brightness_metrics['mean']:.1f}/255, ä¸­ä½æ•°: {brightness_metrics['median']:.1f}",
                    "analysis": f"åŸºäºå¤šé‡äº®åº¦æŒ‡æ ‡åˆ†æ (ç½®ä¿¡åº¦: {brightness_metrics['confidence']:.2f})"
                },
                "contrast": {
                    "name": "å¯¹æ¯”åº¦",
                    "direction": "å¢åŠ " if contrast_adjust > 0 else "é™ä½" if contrast_adjust < 0 else "é€‚ä¸­",
                    "value": contrast_adjust,
                    "unit": "%",
                    "reference": f"å…¨å±€å¯¹æ¯”åº¦: {contrast_metrics['global']:.1f}, å±€éƒ¨å¯¹æ¯”åº¦: {contrast_metrics['local']:.1f}",
                    "analysis": f"åŸºäºå¤šå±‚æ¬¡å¯¹æ¯”åº¦åˆ†æ (ç½®ä¿¡åº¦: {contrast_metrics['confidence']:.2f})"
                },
                "saturation": {
                    "name": "é¥±å’Œåº¦",
                    "direction": "å¢åŠ " if saturation_adjust > 0 else "é™ä½" if saturation_adjust < 0 else "é€‚ä¸­",
                    "value": saturation_adjust,
                    "unit": "%",
                    "reference": f"HSVé¥±å’Œåº¦: {saturation_metrics['hsv']:.1f}, LABè‰²åº¦: {saturation_metrics['lab']:.1f}",
                    "analysis": f"åŸºäºHSV+LABåŒé‡è‰²å½©ç©ºé—´åˆ†æ (ç½®ä¿¡åº¦: {saturation_metrics['confidence']:.2f})"
                },
                "sharpness": {
                    "name": "é”åŒ–",
                    "direction": "å¢å¼º" if sharpness_adjust > 0 else "é€‚ä¸­",
                    "value": sharpness_adjust,
                    "unit": "%",
                    "reference": f"æ‹‰æ™®æ‹‰æ–¯: {sharpness_metrics['laplacian']:.1f}, Sobel: {sharpness_metrics['sobel']:.1f}",
                    "analysis": f"åŸºäºå¤šå°ºåº¦è¾¹ç¼˜æ£€æµ‹ (ç½®ä¿¡åº¦: {sharpness_metrics['confidence']:.2f})"
                },
                "temperature": {
                    "name": "è‰²æ¸©",
                    "direction": "åæš–" if temperature_adjust > 0 else "åå†·" if temperature_adjust < 0 else "ä¸­æ€§",
                    "value": temperature_adjust,
                    "unit": "K",
                    "reference": f"ä¼°è®¡è‰²æ¸©: {temperature_metrics['estimated_temp']:.0f}K, ç™½å¹³è¡¡åå·®: {temperature_metrics['wb_deviation']:.2f}",
                    "analysis": f"åŸºäºç™½å¹³è¡¡ç®—æ³•åˆ†æ (ç½®ä¿¡åº¦: {temperature_metrics['confidence']:.2f})"
                },
                "hue": {
                    "name": "è‰²è°ƒ",
                    "direction": "è°ƒæ•´" if abs(hue_adjust) > 1 else "é€‚ä¸­",
                    "value": hue_adjust,
                    "unit": "Â°",
                    "reference": f"ä¸»å¯¼è‰²è°ƒ: {hue_metrics['dominant_hue']:.1f}Â°, åˆ†å¸ƒæ–¹å·®: {hue_metrics['variance']:.1f}",
                    "analysis": f"åŸºäºä¸»å¯¼è‰²è°ƒæ£€æµ‹ (ç½®ä¿¡åº¦: {hue_metrics['confidence']:.2f})"
                },
                "shadow": {
                    "name": "é˜´å½±",
                    "direction": "æäº®" if shadow_adjust > 0 else "å‹æš—" if shadow_adjust < 0 else "é€‚ä¸­",
                    "value": shadow_adjust,
                    "unit": "%",
                    "reference": f"é˜´å½±åŒºåŸŸå æ¯”: {shadow_highlight_metrics['shadow_ratio']:.1%}",
                    "analysis": f"åŸºäºåŒºåŸŸæ€§é˜´å½±åˆ†æ (ç½®ä¿¡åº¦: {shadow_highlight_metrics['shadow_confidence']:.2f})"
                },
                "highlight": {
                    "name": "é«˜å…‰",
                    "direction": "é™ä½" if highlight_adjust < 0 else "æäº®" if highlight_adjust > 0 else "é€‚ä¸­",
                    "value": highlight_adjust,
                    "unit": "%",
                    "reference": f"é«˜å…‰åŒºåŸŸå æ¯”: {shadow_highlight_metrics['highlight_ratio']:.1%}",
                    "analysis": f"åŸºäºåŒºåŸŸæ€§é«˜å…‰åˆ†æ (ç½®ä¿¡åº¦: {shadow_highlight_metrics['highlight_confidence']:.2f})"
                }
            }, suggestions

        except Exception as e:
            print(f"Image analysis error: {e}")
            raise

    def calculate_brightness_adjustment(self, current_brightness):
        """è®¡ç®—äº®åº¦è°ƒæ•´å»ºè®®"""
        # ç†æƒ³äº®åº¦èŒƒå›´: 120-140
        if current_brightness < 80:
            return round(25 + (80 - current_brightness) * 0.3, 1)
        elif current_brightness < 120:
            return round((120 - current_brightness) * 0.8, 1)
        elif current_brightness > 180:
            return round(-(current_brightness - 180) * 0.5, 1)
        elif current_brightness > 140:
            return round(-(current_brightness - 140) * 0.3, 1)
        return 0.0

    def calculate_contrast_adjustment(self, current_contrast):
        """è®¡ç®—å¯¹æ¯”åº¦è°ƒæ•´å»ºè®®"""
        # ç†æƒ³å¯¹æ¯”åº¦èŒƒå›´: 45-65
        if current_contrast < 30:
            return round(30 + (30 - current_contrast) * 0.6, 1)
        elif current_contrast < 45:
            return round((45 - current_contrast) * 0.8, 1)
        elif current_contrast > 80:
            return round(-(current_contrast - 80) * 0.4, 1)
        return 0.0

    def calculate_saturation_adjustment(self, current_saturation):
        """è®¡ç®—é¥±å’Œåº¦è°ƒæ•´å»ºè®®"""
        # ç†æƒ³é¥±å’Œåº¦èŒƒå›´: 100-140
        if current_saturation < 80:
            return round(15 + (80 - current_saturation) * 0.3, 1)
        elif current_saturation < 100:
            return round((100 - current_saturation) * 0.5, 1)
        elif current_saturation > 160:
            return round(-(current_saturation - 160) * 0.3, 1)
        return 0.0

    def calculate_sharpness_adjustment(self, current_sharpness):
        """è®¡ç®—é”åŒ–è°ƒæ•´å»ºè®®"""
        # é”åŒ–åŸºäºå›¾åƒçš„æ¸…æ™°åº¦
        if current_sharpness < 100:
            return round(20 + (100 - current_sharpness) * 0.1, 1)
        elif current_sharpness < 300:
            return round((300 - current_sharpness) * 0.05, 1)
        return 0.0

    def calculate_temperature_adjustment(self, r_avg, g_avg, b_avg):
        """è®¡ç®—è‰²æ¸©è°ƒæ•´å»ºè®®"""
        # åˆ†æRGBæ¯”å€¼æ¥åˆ¤æ–­è‰²æ¸©åå‘
        if r_avg > g_avg * 1.1 and r_avg > b_avg * 1.2:
            return -100  # åæš–ï¼Œå»ºè®®é™ä½è‰²æ¸©
        elif b_avg > r_avg * 1.1 and b_avg > g_avg * 1.1:
            return 100   # åå†·ï¼Œå»ºè®®æé«˜è‰²æ¸©
        return 0

    def calculate_hue_adjustment(self, current_hue):
        """è®¡ç®—è‰²è°ƒè°ƒæ•´å»ºè®®"""
        # åŸºäºä¸»è¦è‰²è°ƒè¿›è¡Œå¾®è°ƒ
        if 15 <= current_hue <= 45:  # æ©™è‰²èŒƒå›´
            return -2.0  # ç¨å¾®åçº¢
        elif 45 <= current_hue <= 75:  # é»„è‰²èŒƒå›´
            return 1.0   # ç¨å¾®åç»¿
        elif 100 <= current_hue <= 130:  # ç»¿è‰²èŒƒå›´
            return -1.0  # ç¨å¾®åé»„
        return 0.0

    def analyze_shadow_highlight(self, img_gray):
        """åˆ†æé˜´å½±å’Œé«˜å…‰"""
        # è®¡ç®—é˜´å½±åŒºåŸŸï¼ˆä½äº25%çš„åƒç´ ï¼‰
        shadow_mask = img_gray < 64  # 0-63ä¸ºé˜´å½±
        shadow_ratio = np.sum(shadow_mask) / img_gray.size

        # è®¡ç®—é«˜å…‰åŒºåŸŸï¼ˆé«˜äº75%çš„åƒç´ ï¼‰
        highlight_mask = img_gray > 192  # 192-255ä¸ºé«˜å…‰
        highlight_ratio = np.sum(highlight_mask) / img_gray.size

        shadow_adjust = 0.0
        highlight_adjust = 0.0

        # é˜´å½±è¿‡å¤šï¼Œå»ºè®®æäº®
        if shadow_ratio > 0.3:
            shadow_adjust = round(15 + (shadow_ratio - 0.3) * 30, 1)
        elif shadow_ratio > 0.2:
            shadow_adjust = round((shadow_ratio - 0.2) * 50, 1)

        # é«˜å…‰è¿‡å¤šï¼Œå»ºè®®é™ä½
        if highlight_ratio > 0.15:
            highlight_adjust = round(-10 - (highlight_ratio - 0.15) * 40, 1)
        elif highlight_ratio > 0.1:
            highlight_adjust = round(-(highlight_ratio - 0.1) * 60, 1)

        return shadow_adjust, highlight_adjust

    def generate_intelligent_suggestions(self, brightness, contrast, saturation, sharpness, r, g, b):
        """ç”Ÿæˆæ™ºèƒ½åŒ–å»ºè®®"""
        suggestions = []

        # åŸºäºäº®åº¦çš„å»ºè®®
        if brightness < 100:
            suggestions.append("å›¾ç‰‡æ•´ä½“åæš—ï¼Œå»ºè®®å¢åŠ æ›å…‰å’Œé˜´å½±æäº®")
        elif brightness > 160:
            suggestions.append("å›¾ç‰‡æ•´ä½“åäº®ï¼Œå»ºè®®é™ä½é«˜å…‰å’Œæ•´ä½“æ›å…‰")

        # åŸºäºå¯¹æ¯”åº¦çš„å»ºè®®
        if contrast < 40:
            suggestions.append("å›¾ç‰‡å¯¹æ¯”åº¦åä½ï¼Œå»ºè®®å¢åŠ å¯¹æ¯”åº¦ä»¥æå‡å±‚æ¬¡æ„Ÿ")
        elif contrast > 70:
            suggestions.append("å›¾ç‰‡å¯¹æ¯”åº¦è¾ƒé«˜ï¼Œå»ºè®®é€‚å½“é™ä½ä»¥è·å¾—æŸ”å’Œæ•ˆæœ")

        # åŸºäºé¥±å’Œåº¦çš„å»ºè®®
        if saturation < 90:
            suggestions.append("è‰²å½©é¥±å’Œåº¦åä½ï¼Œå»ºè®®é€‚å½“å¢åŠ ä»¥æå‡è‰²å½©é²œæ˜åº¦")
        elif saturation > 150:
            suggestions.append("è‰²å½©è¿‡äºé¥±å’Œï¼Œå»ºè®®é€‚å½“é™ä½ä»¥è·å¾—è‡ªç„¶æ•ˆæœ")

        # åŸºäºè‰²æ¸©çš„å»ºè®®
        if r > g * 1.1:
            suggestions.append("å›¾ç‰‡è‰²è°ƒåæš–ï¼Œå¦‚éœ€è‡ªç„¶æ•ˆæœå¯é€‚å½“é™ä½è‰²æ¸©")
        elif b > r * 1.1:
            suggestions.append("å›¾ç‰‡è‰²è°ƒåå†·ï¼Œå¯é€‚å½“æé«˜è‰²æ¸©å¢åŠ æ¸©æš–æ„Ÿ")

        # åŸºäºé”åº¦çš„å»ºè®®
        if sharpness < 200:
            suggestions.append("å›¾ç‰‡æ¸…æ™°åº¦ä¸€èˆ¬ï¼Œå»ºè®®é€‚å½“å¢åŠ é”åŒ–ä»¥æå‡ç»†èŠ‚")

        # å¦‚æœæ²¡æœ‰æ˜æ˜¾é—®é¢˜ï¼Œç»™å‡ºé€šç”¨å»ºè®®
        if len(suggestions) == 0:
            suggestions.append("å›¾ç‰‡æ•´ä½“æ›å…‰å’Œè‰²å½©å¹³è¡¡è‰¯å¥½ï¼Œå¯æ ¹æ®ä¸ªäººåå¥½å¾®è°ƒ")

        # æœ€å¤šè¿”å›3ä¸ªå»ºè®®
        return suggestions[:3]

    # ========== å¢å¼ºçš„å›¾åƒåˆ†æç®—æ³• ==========

    def analyze_brightness_advanced(self, img_gray, img_lab):
        """å¢å¼ºçš„äº®åº¦åˆ†æ"""
        # å¤šç§äº®åº¦æŒ‡æ ‡
        mean_brightness = np.mean(img_gray)
        median_brightness = np.median(img_gray)
        # LABé¢œè‰²ç©ºé—´ä¸­çš„Lé€šé“æ›´å‡†ç¡®è¡¨ç¤ºäº®åº¦
        lab_brightness = np.mean(img_lab[:, :, 0])

        # ç›´æ–¹å›¾åˆ†æ
        hist = cv2.calcHist([img_gray], [0], None, [256], [0, 256])
        hist_peak = np.argmax(hist)

        # è®¡ç®—äº®åº¦åˆ†å¸ƒçš„åæ–œåº¦
        brightness_std = np.std(img_gray)

        # ç½®ä¿¡åº¦è®¡ç®—ï¼šåŸºäºå¤šæŒ‡æ ‡çš„ä¸€è‡´æ€§
        indicators = [mean_brightness, median_brightness, lab_brightness * 2.55, hist_peak]
        confidence = 1.0 - (np.std(indicators) / np.mean(indicators))
        confidence = max(0.5, min(1.0, confidence))

        return {
            'mean': mean_brightness,
            'median': median_brightness,
            'lab': lab_brightness,
            'hist_peak': hist_peak,
            'std': brightness_std,
            'confidence': confidence
        }

    def calculate_brightness_adjustment_advanced(self, metrics):
        """åŸºäºå¢å¼ºæŒ‡æ ‡çš„äº®åº¦è°ƒæ•´"""
        # ä½¿ç”¨åŠ æƒå¹³å‡ï¼ŒLAB Lé€šé“æƒé‡æ›´é«˜
        weighted_brightness = (metrics['mean'] * 0.3 +
                              metrics['median'] * 0.2 +
                              metrics['lab'] * 2.55 * 0.4 +
                              metrics['hist_peak'] * 0.1)

        # ç†æƒ³äº®åº¦èŒƒå›´: 120-140
        if weighted_brightness < 80:
            return round(30 + (80 - weighted_brightness) * 0.4, 1)
        elif weighted_brightness < 120:
            return round((120 - weighted_brightness) * 0.8, 1)
        elif weighted_brightness > 180:
            return round(-(weighted_brightness - 180) * 0.6, 1)
        elif weighted_brightness > 140:
            return round(-(weighted_brightness - 140) * 0.4, 1)
        return 0.0

    def analyze_contrast_advanced(self, img_gray):
        """å¢å¼ºçš„å¯¹æ¯”åº¦åˆ†æ"""
        # å…¨å±€å¯¹æ¯”åº¦ï¼ˆæ ‡å‡†å·®ï¼‰
        global_contrast = np.std(img_gray)

        # å±€éƒ¨å¯¹æ¯”åº¦ï¼ˆMichelsonå¯¹æ¯”åº¦ï¼‰
        kernel = np.ones((5, 5), np.float32) / 25
        local_mean = cv2.filter2D(img_gray.astype(np.float32), -1, kernel)
        local_contrast = np.mean(np.abs(img_gray.astype(np.float32) - local_mean))

        # RMSå¯¹æ¯”åº¦
        mean_val = np.mean(img_gray)
        rms_contrast = np.sqrt(np.mean((img_gray - mean_val) ** 2))

        # åŸºäºç›´æ–¹å›¾çš„å¯¹æ¯”åº¦
        hist = cv2.calcHist([img_gray], [0], None, [256], [0, 256]).flatten()
        hist_spread = np.sum(hist * np.arange(256)) / np.sum(hist)

        # ç½®ä¿¡åº¦
        contrasts = [global_contrast, local_contrast, rms_contrast]
        confidence = 1.0 - (np.std(contrasts) / (np.mean(contrasts) + 1e-6))
        confidence = max(0.6, min(1.0, confidence))

        return {
            'global': global_contrast,
            'local': local_contrast,
            'rms': rms_contrast,
            'hist_spread': hist_spread,
            'confidence': confidence
        }

    def calculate_contrast_adjustment_advanced(self, metrics):
        """åŸºäºå¢å¼ºæŒ‡æ ‡çš„å¯¹æ¯”åº¦è°ƒæ•´"""
        # åŠ æƒå¯¹æ¯”åº¦
        weighted_contrast = (metrics['global'] * 0.4 +
                            metrics['local'] * 0.3 +
                            metrics['rms'] * 0.3)

        if weighted_contrast < 25:
            return round(35 + (25 - weighted_contrast) * 0.8, 1)
        elif weighted_contrast < 40:
            return round((40 - weighted_contrast) * 1.0, 1)
        elif weighted_contrast > 90:
            return round(-(weighted_contrast - 90) * 0.5, 1)
        return 0.0

    def analyze_saturation_advanced(self, img_hsv, img_lab):
        """å¢å¼ºçš„é¥±å’Œåº¦åˆ†æ"""
        # HSVç©ºé—´çš„é¥±å’Œåº¦
        hsv_saturation = np.mean(img_hsv[:, :, 1])

        # LABç©ºé—´çš„è‰²åº¦ï¼ˆAå’ŒBé€šé“ï¼‰
        a_channel = img_lab[:, :, 1].astype(np.float32) - 128
        b_channel = img_lab[:, :, 2].astype(np.float32) - 128
        lab_chroma = np.mean(np.sqrt(a_channel**2 + b_channel**2))

        # é¥±å’Œåº¦åˆ†å¸ƒåˆ†æ
        sat_std = np.std(img_hsv[:, :, 1])

        # é«˜é¥±å’Œåº¦åƒç´ æ¯”ä¾‹
        high_sat_ratio = np.sum(img_hsv[:, :, 1] > 128) / img_hsv[:, :, 1].size

        # ç½®ä¿¡åº¦
        confidence = min(1.0, (hsv_saturation / 255) * 2 + 0.3)

        return {
            'hsv': hsv_saturation,
            'lab': lab_chroma,
            'std': sat_std,
            'high_sat_ratio': high_sat_ratio,
            'confidence': confidence
        }

    def calculate_saturation_adjustment_advanced(self, metrics):
        """åŸºäºå¢å¼ºæŒ‡æ ‡çš„é¥±å’Œåº¦è°ƒæ•´"""
        # HSVå’ŒLABçš„ç»¼åˆè¯„ä¼°
        normalized_lab = min(metrics['lab'] * 2, 255)  # å½’ä¸€åŒ–LABè‰²åº¦
        weighted_saturation = metrics['hsv'] * 0.6 + normalized_lab * 0.4

        if weighted_saturation < 60:
            return round(20 + (60 - weighted_saturation) * 0.4, 1)
        elif weighted_saturation < 90:
            return round((90 - weighted_saturation) * 0.6, 1)
        elif weighted_saturation > 180:
            return round(-(weighted_saturation - 180) * 0.4, 1)
        return 0.0

    def analyze_sharpness_advanced(self, img_gray):
        """å¢å¼ºçš„é”åº¦åˆ†æ"""
        # æ‹‰æ™®æ‹‰æ–¯ç®—å­
        laplacian = cv2.Laplacian(img_gray, cv2.CV_64F)
        laplacian_var = laplacian.var()

        # Sobelç®—å­
        sobelx = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=3)
        sobel_combined = np.sqrt(sobelx**2 + sobely**2)
        sobel_mean = np.mean(sobel_combined)

        # é«˜é¢‘å†…å®¹åˆ†æ
        f_transform = np.fft.fft2(img_gray)
        f_shift = np.fft.fftshift(f_transform)
        magnitude = np.abs(f_shift)
        h, w = img_gray.shape
        high_freq = magnitude[h//4:3*h//4, w//4:3*w//4]
        high_freq_energy = np.mean(high_freq)

        # ç½®ä¿¡åº¦
        sharpness_indicators = [laplacian_var / 1000, sobel_mean / 100]
        confidence = min(1.0, np.mean(sharpness_indicators) / 50 + 0.4)

        return {
            'laplacian': laplacian_var,
            'sobel': sobel_mean,
            'high_freq': high_freq_energy,
            'confidence': confidence
        }

    def calculate_sharpness_adjustment_advanced(self, metrics):
        """åŸºäºå¢å¼ºæŒ‡æ ‡çš„é”åº¦è°ƒæ•´"""
        # ç»¼åˆé”åº¦è¯„ä¼°
        normalized_laplacian = min(metrics['laplacian'] / 100, 50)
        normalized_sobel = min(metrics['sobel'] / 10, 50)
        weighted_sharpness = normalized_laplacian * 0.6 + normalized_sobel * 0.4

        if weighted_sharpness < 10:
            return round(25 + (10 - weighted_sharpness) * 1.5, 1)
        elif weighted_sharpness < 20:
            return round((20 - weighted_sharpness) * 1.0, 1)
        return 0.0

    def analyze_temperature_advanced(self, img_rgb):
        """å¢å¼ºçš„è‰²æ¸©åˆ†æ"""
        # åŸºç¡€RGBåˆ†æ
        r_avg, g_avg, b_avg = np.mean(img_rgb[:, :, 0]), np.mean(img_rgb[:, :, 1]), np.mean(img_rgb[:, :, 2])

        # ç™½å¹³è¡¡åˆ†æ - ç°åº¦ä¸–ç•Œå‡è®¾
        gray_world_r = r_avg / (r_avg + g_avg + b_avg)
        gray_world_g = g_avg / (r_avg + g_avg + b_avg)
        gray_world_b = b_avg / (r_avg + g_avg + b_avg)

        # ä¼°è®¡è‰²æ¸© (ç®€åŒ–çš„ç®—æ³•)
        if b_avg > 0:
            color_temp_ratio = r_avg / b_avg
            estimated_temp = 6500 / color_temp_ratio if color_temp_ratio > 0 else 6500
        else:
            estimated_temp = 6500

        # ç™½å¹³è¡¡åå·®
        ideal_gray = 1/3
        wb_deviation = abs(gray_world_r - ideal_gray) + abs(gray_world_g - ideal_gray) + abs(gray_world_b - ideal_gray)

        # ç½®ä¿¡åº¦
        confidence = max(0.5, 1.0 - wb_deviation * 3)

        return {
            'r_avg': r_avg,
            'g_avg': g_avg,
            'b_avg': b_avg,
            'estimated_temp': estimated_temp,
            'wb_deviation': wb_deviation,
            'confidence': confidence
        }

    def calculate_temperature_adjustment_advanced(self, metrics):
        """åŸºäºå¢å¼ºæŒ‡æ ‡çš„è‰²æ¸©è°ƒæ•´"""
        estimated_temp = metrics['estimated_temp']

        # ç›®æ ‡è‰²æ¸©6500K
        if estimated_temp < 5000:
            return round((5500 - estimated_temp) / 50, 0)  # åå†·ï¼Œéœ€è¦åŠ æ¸©
        elif estimated_temp > 7500:
            return round(-(estimated_temp - 7000) / 50, 0)  # åæš–ï¼Œéœ€è¦é™æ¸©
        return 0

    def analyze_hue_advanced(self, img_hsv):
        """å¢å¼ºçš„è‰²è°ƒåˆ†æ"""
        hue_channel = img_hsv[:, :, 0]

        # ä¸»å¯¼è‰²è°ƒ
        hue_hist = cv2.calcHist([hue_channel], [0], None, [180], [0, 180])
        dominant_hue = np.argmax(hue_hist)

        # è‰²è°ƒåˆ†å¸ƒ
        hue_mean = np.mean(hue_channel[hue_channel > 0])  # æ’é™¤æ— è‰²è°ƒçš„åƒç´ 
        hue_std = np.std(hue_channel[hue_channel > 0])

        # è‰²è°ƒé›†ä¸­åº¦
        hue_concentration = np.sum(hue_hist > np.max(hue_hist) * 0.1) / 180

        # ç½®ä¿¡åº¦
        confidence = min(1.0, (1 - hue_concentration) + 0.3)

        return {
            'dominant_hue': dominant_hue * 2,  # è½¬æ¢ä¸º360åº¦åˆ¶
            'mean': hue_mean * 2,
            'variance': hue_std,
            'concentration': hue_concentration,
            'confidence': confidence
        }

    def calculate_hue_adjustment_advanced(self, metrics):
        """åŸºäºå¢å¼ºæŒ‡æ ‡çš„è‰²è°ƒè°ƒæ•´"""
        dominant_hue = metrics['dominant_hue']

        # æ ¹æ®ä¸»å¯¼è‰²è°ƒè¿›è¡Œç»†å¾®è°ƒæ•´
        if 15 <= dominant_hue <= 45:  # æ©™è‰²èŒƒå›´
            return -3.0
        elif 45 <= dominant_hue <= 75:  # é»„è‰²èŒƒå›´
            return 2.0
        elif 75 <= dominant_hue <= 150:  # ç»¿è‰²èŒƒå›´
            return -1.0
        elif 280 <= dominant_hue <= 320:  # ç´«è‰²èŒƒå›´
            return 2.0
        return 0.0

    def analyze_shadow_highlight_advanced(self, img_gray, img_rgb):
        """å¢å¼ºçš„é˜´å½±/é«˜å…‰åˆ†æ"""
        # åŠ¨æ€é˜ˆå€¼è®¡ç®—
        mean_brightness = np.mean(img_gray)
        shadow_threshold = max(mean_brightness * 0.3, 32)
        highlight_threshold = min(mean_brightness * 1.8, 224)

        # é˜´å½±åˆ†æ
        shadow_mask = img_gray < shadow_threshold
        shadow_ratio = np.sum(shadow_mask) / img_gray.size
        shadow_mean = np.mean(img_gray[shadow_mask]) if np.sum(shadow_mask) > 0 else 0

        # é«˜å…‰åˆ†æ
        highlight_mask = img_gray > highlight_threshold
        highlight_ratio = np.sum(highlight_mask) / img_gray.size
        highlight_mean = np.mean(img_gray[highlight_mask]) if np.sum(highlight_mask) > 0 else 255

        # ä¸­é—´è°ƒåˆ†æ
        midtone_mask = (img_gray >= shadow_threshold) & (img_gray <= highlight_threshold)
        midtone_ratio = np.sum(midtone_mask) / img_gray.size

        # ç½®ä¿¡åº¦
        shadow_confidence = min(1.0, shadow_ratio * 5 + 0.3)
        highlight_confidence = min(1.0, highlight_ratio * 5 + 0.3)

        return {
            'shadow_ratio': shadow_ratio,
            'shadow_mean': shadow_mean,
            'highlight_ratio': highlight_ratio,
            'highlight_mean': highlight_mean,
            'midtone_ratio': midtone_ratio,
            'shadow_confidence': shadow_confidence,
            'highlight_confidence': highlight_confidence
        }

    def calculate_shadow_highlight_adjustment_advanced(self, metrics):
        """åŸºäºå¢å¼ºæŒ‡æ ‡çš„é˜´å½±/é«˜å…‰è°ƒæ•´"""
        shadow_adjust = 0.0
        highlight_adjust = 0.0

        # é˜´å½±è°ƒæ•´
        if metrics['shadow_ratio'] > 0.4:  # é˜´å½±è¿‡å¤š
            shadow_adjust = round(20 + (metrics['shadow_ratio'] - 0.4) * 40, 1)
        elif metrics['shadow_ratio'] > 0.25:
            shadow_adjust = round((metrics['shadow_ratio'] - 0.25) * 60, 1)

        # é«˜å…‰è°ƒæ•´
        if metrics['highlight_ratio'] > 0.2:  # é«˜å…‰è¿‡å¤š
            highlight_adjust = round(-15 - (metrics['highlight_ratio'] - 0.2) * 50, 1)
        elif metrics['highlight_ratio'] > 0.1:
            highlight_adjust = round(-(metrics['highlight_ratio'] - 0.1) * 80, 1)

        return shadow_adjust, highlight_adjust

    def generate_intelligent_suggestions_advanced(self, brightness_metrics, contrast_metrics,
                                                 saturation_metrics, sharpness_metrics,
                                                 temperature_metrics, hue_metrics):
        """ç”Ÿæˆå¢å¼ºçš„æ™ºèƒ½åŒ–å»ºè®®"""
        suggestions = []

        # åŸºäºç½®ä¿¡åº¦çš„å»ºè®®
        high_confidence_threshold = 0.8

        # äº®åº¦å»ºè®®
        if brightness_metrics['confidence'] > high_confidence_threshold:
            if brightness_metrics['mean'] < 100:
                suggestions.append(f"å›¾ç‰‡æ•´ä½“åæš—(ç½®ä¿¡åº¦: {brightness_metrics['confidence']:.1%})ï¼Œå»ºè®®å¢åŠ æ›å…‰å’Œé˜´å½±æäº®")
            elif brightness_metrics['mean'] > 160:
                suggestions.append(f"å›¾ç‰‡æ•´ä½“åäº®(ç½®ä¿¡åº¦: {brightness_metrics['confidence']:.1%})ï¼Œå»ºè®®é™ä½é«˜å…‰å’Œæ•´ä½“æ›å…‰")

        # å¯¹æ¯”åº¦å»ºè®®
        if contrast_metrics['confidence'] > high_confidence_threshold:
            if contrast_metrics['global'] < 35:
                suggestions.append(f"å›¾ç‰‡å¯¹æ¯”åº¦åä½(ç½®ä¿¡åº¦: {contrast_metrics['confidence']:.1%})ï¼Œå»ºè®®å¢åŠ å¯¹æ¯”åº¦ä»¥æå‡å±‚æ¬¡æ„Ÿ")

        # é¥±å’Œåº¦å»ºè®®
        if saturation_metrics['confidence'] > 0.7:  # è¾ƒä½é˜ˆå€¼ï¼Œå› ä¸ºé¥±å’Œåº¦åˆ†æç›¸å¯¹å›°éš¾
            if saturation_metrics['hsv'] < 80:
                suggestions.append(f"è‰²å½©é¥±å’Œåº¦åä½(ç½®ä¿¡åº¦: {saturation_metrics['confidence']:.1%})ï¼Œå»ºè®®é€‚å½“å¢åŠ ä»¥æå‡è‰²å½©é²œæ˜åº¦")

        # é”åº¦å»ºè®®
        if sharpness_metrics['confidence'] > 0.6:
            if sharpness_metrics['laplacian'] < 150:
                suggestions.append(f"å›¾ç‰‡æ¸…æ™°åº¦ä¸€èˆ¬(ç½®ä¿¡åº¦: {sharpness_metrics['confidence']:.1%})ï¼Œå»ºè®®é€‚å½“å¢åŠ é”åŒ–ä»¥æå‡ç»†èŠ‚")

        # è‰²æ¸©å»ºè®®
        if temperature_metrics['confidence'] > 0.7:
            if temperature_metrics['estimated_temp'] < 5000:
                suggestions.append(f"å›¾ç‰‡è‰²è°ƒåå†·(è‰²æ¸©çº¦{temperature_metrics['estimated_temp']:.0f}K)ï¼Œå¯é€‚å½“æé«˜è‰²æ¸©å¢åŠ æ¸©æš–æ„Ÿ")
            elif temperature_metrics['estimated_temp'] > 7500:
                suggestions.append(f"å›¾ç‰‡è‰²è°ƒåæš–(è‰²æ¸©çº¦{temperature_metrics['estimated_temp']:.0f}K)ï¼Œå¦‚éœ€è‡ªç„¶æ•ˆæœå¯é€‚å½“é™ä½è‰²æ¸©")

        # é€šç”¨å»ºè®®
        if len(suggestions) == 0:
            suggestions.append("å›¾ç‰‡æ•´ä½“æ›å…‰å’Œè‰²å½©å¹³è¡¡è‰¯å¥½ï¼Œå¯æ ¹æ®ä¸ªäººåå¥½è¿›è¡Œå¾®è°ƒ")
        elif len(suggestions) > 3:
            # æ ¹æ®ç½®ä¿¡åº¦æ’åºï¼Œä¿ç•™å‰3ä¸ª
            suggestions = suggestions[:3]

        return suggestions

    def handle_analyze(self, api_path):
        print("=== REAL IMAGE ANALYSIS ===")
        image_id = api_path.split('/')[-1]
        print(f"Analyzing image: {image_id}")

        try:
            # æŸ¥æ‰¾ä¸´æ—¶æ–‡ä»¶
            temp_dir = tempfile.gettempdir()
            temp_path = os.path.join(temp_dir, f"{image_id}.jpg")

            if not os.path.exists(temp_path):
                self.send_json_error(404, "å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°ä¸Šä¼ ")
                return

            start_time = time.time()

            # è¿›è¡ŒçœŸå®çš„å›¾åƒåˆ†æ
            parameters, suggestions = self.analyze_image_with_opencv(temp_path)

            analysis_time = round(time.time() - start_time, 1)

            response_data = {
                "status": "success",
                "message": "å›¾åƒåˆ†æå®Œæˆ",
                "data": {
                    "image_id": image_id,
                    "parameters": parameters,
                    "analysis_time": analysis_time,
                    "confidence_score": 0.92,  # åŸºäºOpenCVåˆ†æçš„å¯ä¿¡åº¦è¾ƒé«˜
                    "suggestions": suggestions,
                    "analysis_method": "OpenCVè®¡ç®—æœºè§†è§‰åˆ†æ"
                }
            }
            print("Sending real analysis response")
            self.send_json_response(response_data)

        except Exception as e:
            print(f"Analysis error: {e}")
            self.send_json_error(500, f"å›¾åƒåˆ†æå¤±è´¥: {str(e)}")

    def handle_generate(self):
        print("=== GENERATE REQUEST ===")

        try:
            content_length = int(self.headers.get('Content-Length', 0))
            if content_length > 0:
                post_data = self.rfile.read(content_length)
                data = json.loads(post_data.decode('utf-8'))
                print(f"Generate request data: {data}")

                # è·å–åŸå§‹å›¾ç‰‡å’Œæ»¤é•œå‚æ•°
                image_id = data.get("original_image_id", "")
                filter_parameters = data.get("parameters", {})

                if not image_id:
                    self.send_json_error(400, "Missing original_image_id")
                    return

                # æŸ¥æ‰¾åŸå§‹å›¾ç‰‡
                temp_dir = tempfile.gettempdir()
                image_path = os.path.join(temp_dir, f"{image_id}.jpg")

                if not os.path.exists(image_path):
                    # å¦‚æœæ‰¾ä¸åˆ°æŒ‡å®šå›¾ç‰‡ï¼Œä½¿ç”¨æœ€æ–°ä¸Šä¼ çš„å›¾ç‰‡
                    image_files = []
                    for filename in os.listdir(temp_dir):
                        if filename.startswith('img_') and filename.endswith('.jpg'):
                            file_path = os.path.join(temp_dir, filename)
                            if os.path.exists(file_path):
                                image_files.append((file_path, os.path.getmtime(file_path)))

                    if not image_files:
                        self.send_json_error(404, "No uploaded image found")
                        return

                    # ä½¿ç”¨æœ€æ–°ä¸Šä¼ çš„å›¾ç‰‡
                    image_files.sort(key=lambda x: x[1], reverse=True)
                    image_path = image_files[0][0]

                print(f"Processing image: {image_path}")

                # åº”ç”¨æ»¤é•œå¤„ç†ç”Ÿæˆæ–°å›¾ç‰‡
                output_id = f"output_{int(time.time() * 1000)}"
                processed_image_data = self.apply_filter_to_image(image_path, filter_parameters)

                if processed_image_data:
                    # ä¿å­˜å¤„ç†åçš„å›¾ç‰‡åˆ°ä¸´æ—¶ç›®å½•
                    processed_image_path = os.path.join(temp_dir, f"{output_id}.jpg")
                    with open(processed_image_path, 'wb') as f:
                        f.write(processed_image_data)

                    # ä¿å­˜æ»¤é•œä¿¡æ¯åˆ°ä¸´æ—¶æ–‡ä»¶
                    filter_info_path = os.path.join(temp_dir, f"{output_id}_filter.json")
                    filter_info = {
                        "output_id": output_id,
                        "image_id": image_id,
                        "filter_parameters": filter_parameters,
                        "timestamp": time.time(),
                        "processed_image_path": processed_image_path
                    }

                    with open(filter_info_path, 'w') as f:
                        json.dump(filter_info, f)

                    print(f"Saved processed image to: {processed_image_path}")
                    print(f"Saved filter info to: {filter_info_path}")

                    response_data = {
                        "status": "success",
                        "message": "æ»¤é•œç”Ÿæˆå®Œæˆ",
                        "data": {
                            "output_image_id": output_id,
                            "output_filename": f"{output_id}.jpg",
                            "processing_time": 1.5,
                            "preview_url": f"/api/preview/{output_id}",
                            "download_url": f"/api/download/{output_id}"
                        }
                    }
                else:
                    response_data = {
                        "status": "error",
                        "message": "Failed to process image with filters"
                    }
            else:
                response_data = {
                    "status": "error",
                    "message": "No data received"
                }

            print("Sending generate response")
            self.send_json_response(response_data)

        except Exception as e:
            print(f"Generate error: {e}")
            import traceback
            traceback.print_exc()
            self.send_json_error(500, f"Generate failed: {str(e)}")

    def handle_preview(self, api_path):
        print("=== PREVIEW REQUEST ===")
        output_id = api_path.split('/')[-1]
        print(f"Preview output: {output_id}")

        try:
            temp_dir = tempfile.gettempdir()
            processed_image_path = os.path.join(temp_dir, f"{output_id}.jpg")

            if os.path.exists(processed_image_path):
                # è¯»å–å¤„ç†åçš„å›¾ç‰‡
                with open(processed_image_path, 'rb') as f:
                    image_data = f.read()

                # è®¾ç½®æ­£ç¡®çš„å“åº”å¤´
                self.send_response(200)
                self.send_header('Content-Type', 'image/jpeg')
                self.send_header('Cache-Control', 'no-cache, no-store, must-revalidate')
                self.send_header('Pragma', 'no-cache')
                self.send_header('Expires', '0')
                self.send_header('Content-Length', str(len(image_data)))
                self.end_headers()

                # å‘é€å›¾ç‰‡æ•°æ®
                self.wfile.write(image_data)
                print(f"Successfully sent preview image: {len(image_data)} bytes")
            else:
                self.send_json_error(404, "Processed image not found")

        except Exception as e:
            print(f"Preview error: {e}")
            self.send_json_error(500, f"Preview failed: {str(e)}")

    def handle_download(self, api_path):
        print("=== DOWNLOAD REQUEST ===")
        output_id = api_path.split('/')[-1]
        print(f"Downloading output: {output_id}")

        try:
            temp_dir = tempfile.gettempdir()

            # è¯»å–æ»¤é•œä¿¡æ¯
            filter_info_path = os.path.join(temp_dir, f"{output_id}_filter.json")
            filter_info = None

            if os.path.exists(filter_info_path):
                with open(filter_info_path, 'r') as f:
                    filter_info = json.load(f)
                    print(f"Found filter info: {filter_info}")

            # æŸ¥æ‰¾åŸå§‹å›¾ç‰‡
            image_id = filter_info.get("image_id", "") if filter_info else ""
            image_path = None

            if image_id:
                # ä¼˜å…ˆä½¿ç”¨æŒ‡å®šçš„å›¾ç‰‡ID
                image_path = os.path.join(temp_dir, f"{image_id}.jpg")

            # å¦‚æœæ‰¾ä¸åˆ°æŒ‡å®šå›¾ç‰‡ï¼Œä½¿ç”¨æœ€æ–°ä¸Šä¼ çš„å›¾ç‰‡
            if not image_path or not os.path.exists(image_path):
                image_files = []
                for filename in os.listdir(temp_dir):
                    if filename.startswith('img_') and filename.endswith('.jpg'):
                        file_path = os.path.join(temp_dir, filename)
                        if os.path.exists(file_path):
                            image_files.append((file_path, os.path.getmtime(file_path)))

                if not image_files:
                    self.send_json_error(404, "No uploaded image found for processing")
                    return

                # ä½¿ç”¨æœ€æ–°ä¸Šä¼ çš„å›¾ç‰‡
                image_files.sort(key=lambda x: x[1], reverse=True)
                image_path = image_files[0][0]

            print(f"Using image: {image_path}")

            if os.path.exists(image_path):
                # åº”ç”¨æ»¤é•œå¤„ç†
                processed_image_data = self.apply_filter_to_image(
                    image_path,
                    filter_info.get("filter_parameters", {}) if filter_info else {}
                )

                if processed_image_data:
                    # è®¾ç½®æ­£ç¡®çš„å“åº”å¤´
                    self.send_response(200)
                    self.send_header('Content-Type', 'image/jpeg')
                    self.send_header('Content-Disposition', f'attachment; filename="enhanced_{output_id}.jpg"')
                    self.send_header('Content-Length', str(len(processed_image_data)))
                    self.end_headers()

                    # å‘é€å¤„ç†åçš„å›¾ç‰‡æ•°æ®
                    self.wfile.write(processed_image_data)
                    print(f"Successfully sent filtered image: {len(processed_image_data)} bytes")
                else:
                    self.send_json_error(500, "Failed to process image with filters")
            else:
                self.send_json_error(404, "Original image file not found")

        except Exception as e:
            print(f"Download error: {e}")
            self.send_json_error(500, f"Download failed: {str(e)}")

    def apply_filter_to_image(self, image_path, filter_parameters):
        """åº”ç”¨æ»¤é•œå‚æ•°åˆ°å›¾ç‰‡å¹¶è¿”å›å¤„ç†åçš„å›¾ç‰‡æ•°æ®"""
        try:
            # è¯»å–åŸå§‹å›¾ç‰‡
            img = cv2.imread(image_path)
            if img is None:
                print(f"Failed to read image: {image_path}")
                return None

            print(f"Applying filters: {filter_parameters}")

            # è½¬æ¢ä¸ºRGB (OpenCVé»˜è®¤BGR)
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

            # åº”ç”¨äº®åº¦è°ƒæ•´
            if 'brightness' in filter_parameters:
                brightness_param = filter_parameters['brightness']
                if isinstance(brightness_param, dict) and 'value' in brightness_param:
                    brightness_val = brightness_param['value']
                else:
                    brightness_val = brightness_param

                if brightness_val != 0:
                    print(f"Applying brightness: {brightness_val}")
                    # äº®åº¦è°ƒæ•´ï¼šæ·»åŠ å¸¸æ•°å€¼
                    brightness_change = int(brightness_val * 2.5)  # å¢å¼ºæ•ˆæœ
                    # ç¡®ä¿æ•°æ®ç±»å‹åŒ¹é…
                    img_rgb = img_rgb.astype(np.int16)
                    img_rgb = img_rgb + brightness_change
                    img_rgb = np.clip(img_rgb, 0, 255).astype(np.uint8)

            # åº”ç”¨å¯¹æ¯”åº¦è°ƒæ•´
            if 'contrast' in filter_parameters:
                contrast_param = filter_parameters['contrast']
                if isinstance(contrast_param, dict) and 'value' in contrast_param:
                    contrast_val = contrast_param['value']
                else:
                    contrast_val = contrast_param

                if contrast_val != 0:
                    print(f"Applying contrast: {contrast_val}")
                    # å¯¹æ¯”åº¦è°ƒæ•´ï¼šä¹˜ä»¥æ¯”ä¾‹å› å­
                    factor = 1.0 + (contrast_val / 100.0)
                    img_rgb = img_rgb.astype(np.float32)
                    img_rgb = img_rgb * factor
                    img_rgb = np.clip(img_rgb, 0, 255).astype(np.uint8)

            # åº”ç”¨é¥±å’Œåº¦è°ƒæ•´
            if 'saturation' in filter_parameters:
                saturation_param = filter_parameters['saturation']
                if isinstance(saturation_param, dict) and 'value' in saturation_param:
                    saturation_val = saturation_param['value']
                else:
                    saturation_val = saturation_param

                if saturation_val != 0:
                    print(f"Applying saturation: {saturation_val}")
                    # è½¬æ¢åˆ°HSVè¿›è¡Œé¥±å’Œåº¦è°ƒæ•´
                    img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV).astype(np.float32)
                    factor = 1.0 + (saturation_val / 100.0)
                    img_hsv[:, :, 1] = img_hsv[:, :, 1] * factor
                    img_hsv[:, :, 1] = np.clip(img_hsv[:, :, 1], 0, 255)
                    img_rgb = cv2.cvtColor(img_hsv.astype(np.uint8), cv2.COLOR_HSV2RGB)

            # åº”ç”¨è‰²è°ƒè°ƒæ•´
            if 'hue' in filter_parameters:
                hue_param = filter_parameters['hue']
                if isinstance(hue_param, dict) and 'value' in hue_param:
                    hue_val = hue_param['value']
                else:
                    hue_val = hue_param

                if hue_val != 0:
                    print(f"Applying hue: {hue_val}")
                    # è½¬æ¢åˆ°HSVè¿›è¡Œè‰²è°ƒè°ƒæ•´
                    img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV).astype(np.float32)
                    img_hsv[:, :, 0] = (img_hsv[:, :, 0] + hue_val) % 180
                    img_rgb = cv2.cvtColor(img_hsv.astype(np.uint8), cv2.COLOR_HSV2RGB)

            # åº”ç”¨é”åŒ–
            if 'sharpness' in filter_parameters:
                sharpness_param = filter_parameters['sharpness']
                if isinstance(sharpness_param, dict) and 'value' in sharpness_param:
                    sharpness_val = sharpness_param['value']
                else:
                    sharpness_val = sharpness_param

                if sharpness_val > 0:
                    print(f"Applying sharpness: {sharpness_val}")
                    # ä½¿ç”¨é”åŒ–æ ¸
                    amount = sharpness_val / 100.0
                    kernel = np.array([[-1,-1,-1], [-1,9+amount,-1], [-1,-1,-1]])
                    img_rgb = cv2.filter2D(img_rgb, -1, kernel)
                    img_rgb = np.clip(img_rgb, 0, 255).astype(np.uint8)

            # è½¬æ¢å›BGR for JPEGç¼–ç 
            img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)

            # ç¼–ç ä¸ºJPEG
            encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 95]
            is_success, buffer = cv2.imencode(".jpg", img_bgr, encode_param)

            if is_success:
                print(f"Successfully processed image with filters")
                return buffer.tobytes()
            else:
                print("Failed to encode processed image")
                return None

        except Exception as e:
            print(f"Error applying filter: {e}")
            import traceback
            traceback.print_exc()
            return None

    def handle_health(self):
        response_data = {
            "status": "success",
            "message": "Real Image Analysis Serveræ­£å¸¸è¿è¡Œ",
            "data": {
                "timestamp": datetime.now().isoformat(),
                "analysis_engine": "OpenCV + Computer Vision",
                "version": "1.0.0"
            }
        }
        self.send_json_response(response_data)

    def send_json_response(self, data, status_code=200):
        self.send_response(status_code)
        self.send_header('Content-Type', 'application/json; charset=utf-8')
        self.end_headers()
        json_str = json.dumps(data, ensure_ascii=False, indent=2)
        self.wfile.write(json_str.encode('utf-8'))

    def send_json_error(self, status_code, message):
        error_data = {
            "status": "error",
            "message": message,
            "error_code": f"HTTP_{status_code}"
        }
        self.send_json_response(error_data, status_code)

def main():
    PORT = 8080
    os.chdir('/Users/cswenx/program/AICoding/Filter-Parser')

    with socketserver.TCPServer(("", PORT), ImageAnalysisHandler) as httpd:
        print("=" * 70)
        print("ğŸ”¬ Real Image Analysis Server - OpenCV Powered")
        print("=" * 70)
        print(f"ğŸ“ æœåŠ¡åœ°å€: http://localhost:{PORT}")
        print(f"ğŸ§  åˆ†æå¼•æ“: OpenCV + Computer Vision")
        print(f"ğŸ“ å·¥ä½œç›®å½•: {os.getcwd()}")
        print("=" * 70)
        print("âœ¨ åŠŸèƒ½ç‰¹ç‚¹:")
        print("   â€¢ çœŸå®å›¾åƒäº®åº¦ã€å¯¹æ¯”åº¦åˆ†æ")
        print("   â€¢ è‰²å½©é¥±å’Œåº¦å’Œè‰²æ¸©æ£€æµ‹")
        print("   â€¢ å›¾åƒé”åº¦å’Œæ¸…æ™°åº¦è¯„ä¼°")
        print("   â€¢ é˜´å½±/é«˜å…‰åŒºåŸŸåˆ†æ")
        print("   â€¢ æ™ºèƒ½åŒ–å‚æ•°è°ƒæ•´å»ºè®®")
        print("=" * 70)
        print("æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
        print()

        try:
            httpd.serve_forever()
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Real Image Analysis Serverå·²åœæ­¢")

if __name__ == '__main__':
    main()